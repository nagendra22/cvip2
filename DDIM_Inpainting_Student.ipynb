{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfcb1b40",
   "metadata": {},
   "source": [
    "# DDIM Inpainting on MNIST\n",
    "**Learning:** Build a DDIM pipeline for center-hole inpainting: timestep-conditioned U-Net, DDIM sampling, hole-only PSNR/L1.  \n",
    "**Goal:** Train on masked MNIST, then sample reconstructions and evaluate only inside the mask.  \n",
    "> **Tip:** Use **Google Colab (GPU)** and keep batch size modest to avoid OOM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb8157",
   "metadata": {},
   "source": [
    "## 0. Prerequisites (Colab GPU)\n",
    "- In Colab: **Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU â†’ Save**.\n",
    "- CPU works but training will be **much slower**.\n",
    "- This notebook installs only minimal packages.\n",
    "\n",
    "> If you prefer Kaggle: enable GPU in **Settings â†’ Accelerator â†’ GPU**.\n",
    "\n",
    "**Quick GPU check (run once):**\n",
    "```python\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d5a82",
   "metadata": {},
   "source": [
    "## 1. Install minimal dependencies\n",
    "\n",
    "- **Colab users:** PyTorch is already installedâ€”**donâ€™t reinstall `torch`/`torchvision`**. Install only extras below.  \n",
    "- **Non-Colab users:** Use the pinned install shown after the Colab snippet.\n",
    "\n",
    "**Colab (recommended):**\n",
    "```bash\n",
    "!pip -q install -U tqdm matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6f65b",
   "metadata": {},
   "source": [
    "## 2. Check GPU\n",
    "\n",
    "Run this cell to verify that CUDA is available (Colab GPU recommended):\n",
    "\n",
    "```python\n",
    "import torch, platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"MPS available?\", torch.backends.mps.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "elif torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print(\"Running on CPU â€” training will be much slower.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a63f8f",
   "metadata": {},
   "source": [
    "## 3. Quick Equations (reference)\n",
    "\n",
    "**Forward noising**\n",
    "$$\n",
    "x_t=\\sqrt{\\bar{\\alpha}_t}\\,x_0+\\sqrt{1-\\bar{\\alpha}_t}\\,\\varepsilon,\\qquad \\varepsilon\\sim\\mathcal N(0,I)\n",
    "$$\n",
    "\n",
    "**Cosine schedule â€” beta\\_t from abar(t)**\n",
    "$$\n",
    "\\bar{\\alpha}(t)=\\cos^2\\!\\left(\\frac{t/T+s}{1+s}\\cdot\\frac{\\pi}{2}\\right)\n",
    "$$\n",
    "$$\n",
    "\\beta_t=\\min\\!\\left(0.999,\\;1-\\frac{\\bar{\\alpha}(t+1)}{\\bar{\\alpha}(t)}\\right)\n",
    "$$\n",
    "\n",
    "**Prediction-space mapping**\n",
    "- **pred = `eps`**\n",
    "$$\n",
    "\\hat\\varepsilon=\\text{out},\\qquad\n",
    "\\hat x_0=\\frac{x_t-\\sqrt{1-\\bar{\\alpha}_t}\\,\\hat\\varepsilon}{\\sqrt{\\bar{\\alpha}_t}}\n",
    "$$\n",
    "\n",
    "- **pred = `x0`**\n",
    "$$\n",
    "\\hat x_0=\\text{out},\\qquad\n",
    "\\hat\\varepsilon=\\frac{x_t-\\sqrt{\\bar{\\alpha}_t}\\,\\hat x_0}{\\sqrt{1-\\bar{\\alpha}_t}}\n",
    "$$\n",
    "\n",
    "- **pred = `v`**\n",
    "$$\n",
    "\\hat x_0=\\sqrt{\\bar{\\alpha}_t}\\,x_t-\\sqrt{1-\\bar{\\alpha}_t}\\,\\text{out},\\qquad\n",
    "\\hat\\varepsilon=\\sqrt{1-\\bar{\\alpha}_t}\\,x_t+\\sqrt{\\bar{\\alpha}_t}\\,\\text{out}\n",
    "$$\n",
    "\n",
    "**DDIM step** (optional noise eta)\n",
    "$$\n",
    "\\sigma_t=\\eta\\cdot\\sqrt{\\frac{1-\\bar{\\alpha}_{t'}}{1-\\bar{\\alpha}_t}\\left(1-\\frac{\\bar{\\alpha}_t}{\\bar{\\alpha}_{t'}}\\right)}\n",
    "$$\n",
    "$$\n",
    "x_{t'}=\\sqrt{\\bar{\\alpha}_{t'}}\\,\\hat x_0+\\sqrt{1-\\bar{\\alpha}_{t'}-\\sigma_t^{2}}\\,\\hat\\varepsilon+\\mathbf{1}_{\\eta>0}\\,\\sigma_t z\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11714c0",
   "metadata": {},
   "source": [
    "## 4. Utilities & Data _(GIVEN â€” do not modify)_\n",
    "\n",
    "Helper functions used throughout the notebook:\n",
    "- **Repro & device:** `seed_all`, `dev`\n",
    "- **I/O & viz:** `ensure_dir`, `save_grid`, `safe_torch_load`\n",
    "- **Data:** `get_mnist_loader` (MNIST â†’ 32Ã—32, normalized to \\([-1,1]\\))\n",
    "- **Masking:** `make_center_box_mask` (zeros at center box = hole)\n",
    "- **Metrics (hole-only):** `psnr_on_mask`, `l1_on_mask`\n",
    "\n",
    "> Note: `seed_all` sets `cudnn.benchmark=True` for speed (slightly non-deterministic). If you need **strict reproducibility**, temporarily set it to `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, json, random\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils as vutils\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# Utils\n",
    "# ----------------------------\n",
    "def seed_all(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def dev():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True); return p\n",
    "\n",
    "def save_grid(x, path, nrow=8, rng=(-1,1), dpi=220):\n",
    "    ensure_dir(os.path.dirname(path) or \".\")\n",
    "    grid = vutils.make_grid(x, nrow=nrow, normalize=True, value_range=rng)\n",
    "    plt.figure(figsize=(5,5)); plt.axis(\"off\")\n",
    "    arr = grid.detach().cpu().numpy().transpose(1,2,0)\n",
    "    if arr.shape[2] == 1:\n",
    "        arr = np.repeat(arr, 3, axis=2)\n",
    "    plt.imshow(arr); plt.tight_layout(); plt.savefig(path, dpi=dpi); plt.close()\n",
    "\n",
    "def safe_torch_load(path, map_location=\"cpu\"):\n",
    "    try:\n",
    "        return torch.load(path, map_location=map_location, weights_only=True)  # PyTorch â‰¥2.4\n",
    "    except TypeError:\n",
    "        return torch.load(path, map_location=map_location)\n",
    "\n",
    "def get_mnist_loader(batch_size=128, num_workers=2):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32,32), antialias=True),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # [-1,1]\n",
    "    ])\n",
    "    tr = datasets.MNIST('./data', train=True,  transform=tfm, download=True)\n",
    "    te = datasets.MNIST('./data', train=False, transform=tfm, download=True)\n",
    "    train = DataLoader(tr, batch_size, shuffle=True,  num_workers=num_workers, drop_last=True)\n",
    "    test  = DataLoader(te, batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "    return train, test, (1,32,32)\n",
    "\n",
    "# ----------------------------\n",
    "# Masks (centered, fixed size)\n",
    "# ----------------------------\n",
    "def make_center_box_mask(B, H, W, box=12):\n",
    "    m = torch.ones(B,1,H,W)\n",
    "    hs, ws = H//2, W//2\n",
    "    h0, h1 = hs - box//2, hs + box//2\n",
    "    w0, w1 = ws - box//2, ws + box//2\n",
    "    m[:,:,h0:h1,w0:w1] = 0.0\n",
    "    return m\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics (hole region only)\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def psnr_on_mask(pred, target, known_mask, eps=1e-8):\n",
    "    hole = (1.0 - known_mask)\n",
    "    N = hole.sum().clamp_min(1.0)\n",
    "    p = (pred+1)/2; t = (target+1)/2\n",
    "    mse = ((p - t)**2 * hole).sum() / N\n",
    "    return float(10.0 * torch.log10(1.0 / (mse + eps)))\n",
    "\n",
    "@torch.no_grad()\n",
    "def l1_on_mask(pred, target, known_mask):\n",
    "    hole = (1.0 - known_mask)\n",
    "    N = hole.sum().clamp_min(1.0)\n",
    "    return float(((pred - target).abs() * hole).sum() / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdcf64",
   "metadata": {},
   "source": [
    "## 5. Model & Diffusion â€” YOUR IMPLEMENTATIONS (TODO)\n",
    "\n",
    "Youâ€™ll implement the core pieces of the model and sampler. Keep interfaces unchanged; only fill the **TODO** parts. Use the **Quick Equations** section above as reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23565edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embed(t: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    ### TODO: implement sinusoidal timestep embedding Ï•(t) âˆˆ â„^{BÃ—dim}.\n",
    "\n",
    "    Let H = âŒŠdim/2âŒ‹, and frequencies\n",
    "      f_k = exp( - (log 10000) * k / max(1, H-1) ),  k = 0..H-1.\n",
    "\n",
    "    Define\n",
    "      Ï•(t) = [ sin(t f_0), ..., sin(t f_{H-1}),  cos(t f_0), ..., cos(t f_{H-1}) ].\n",
    "    If dim is odd, append one zero column.\n",
    "\n",
    "    Inputs:\n",
    "      t: (B,) Long/float tensor (will cast to float internally)\n",
    "      dim: embedding size\n",
    "    Output:\n",
    "      (B, dim) on same device as t.\n",
    "    \"\"\"\n",
    "    # ====== Implement here ======\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    r\"\"\"\n",
    "    ### TODO: Residual block with time embedding injection\n",
    "\n",
    "    Given input x âˆˆ â„^{BÃ—CÃ—HÃ—W} and time embedding e âˆˆ â„^{BÃ—E},\n",
    "    compute:\n",
    "      h = x + MLP(e)[:, :, None, None]\n",
    "      h = GN(C) â†’ SiLU â†’ Conv2d(Câ†’C, 3Ã—3, s=1, p=1)\n",
    "      h = Dropout2d(p=dropout)\n",
    "      h = GN(C) â†’ SiLU â†’ Conv2d(Câ†’C, 3Ã—3, s=1, p=1)\n",
    "      out = x + h\n",
    "\n",
    "    Use GroupNorm with 'groups' (cap to divisors of C; at least 1).\n",
    "    \"\"\"\n",
    "    def __init__(self, ch: int, emb: int, dropout: float=0.1, groups: int=8):\n",
    "        super().__init__()\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    r\"\"\"\n",
    "    ### TODO: Single-head self-attention at spatial resolution (e.g., 8Ã—8).\n",
    "\n",
    "    Normalize with GroupNorm(8, C).\n",
    "    Compute q,k,v via 1Ã—1 convs (Câ†’C).\n",
    "    Shapes:\n",
    "      x: (B,C,H,W)\n",
    "      q: (B,HW,C)   from (B,C,H,W) â†’ (B,C,HW) â†’ (B,HW,C)\n",
    "      k: (B,C,HW)\n",
    "      v: (B,HW,C)\n",
    "      attn = softmax( (q @ k)/âˆšC , dim=-1 )   â†’ (B,HW,HW)\n",
    "      out  = (attn @ v) â†’ (B,HW,C) â†’ (B,C,H,W) â†’ proj 1Ã—1 â†’ residual add.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch: int):\n",
    "        super().__init__()\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class UNetDeep(nn.Module):\n",
    "    r\"\"\"\n",
    "    ### TODO: Implement the UNet backbone with time-conditioning and mid attention.\n",
    "\n",
    "    Input channels depend on flags:\n",
    "      - Base: [x_t, m, y] â†’ 3 channels\n",
    "      - + self-conditioning: add x0_sc â†’ +1 channel (total 4)\n",
    "      - + coord_conv: add (coord_x, coord_y) â†’ +2 channels (total 5 or 6)\n",
    "\n",
    "    Spec (assume base=B):\n",
    "      t-MLP: Linear(Eâ†’2E) â†’ SiLU â†’ Linear(2Eâ†’E)\n",
    "      Down:\n",
    "        inp:  Conv2d(in_châ†’B, 3Ã—3,1,1)\n",
    "        rb0:  ResBlock(B,E)\n",
    "        d1 :  Conv2d(Bâ†’2B, 4Ã—4,2,1)\n",
    "        rb1:  ResBlock(2B,E)\n",
    "        d2 :  Conv2d(2Bâ†’4B, 4Ã—4,2,1)\n",
    "        rb2:  ResBlock(4B,E)\n",
    "      Mid (8Ã—8):\n",
    "        mid1: ResBlock(4B,E)\n",
    "        attn: SelfAttention2d(4B)\n",
    "        mid2: ResBlock(4B,E)\n",
    "      Up:\n",
    "        u1 :  ConvTranspose2d(4Bâ†’2B, 4Ã—4,2,1)\n",
    "        red1: Conv2d(2B+2Bâ†’2B, 1Ã—1)\n",
    "        rb3:  ResBlock(2B,E)\n",
    "        u2 :  ConvTranspose2d(2Bâ†’B, 4Ã—4,2,1)\n",
    "        red2: Conv2d(B+Bâ†’B, 1Ã—1)\n",
    "        rb4:  ResBlock(B,E)\n",
    "      Out:\n",
    "        Conv2d(Bâ†’1, 3Ã—3,1,1)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, base=96, emb=384, out_ch=1, dropout=0.1, use_attn=True):\n",
    "        super().__init__()\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Diffusion core (buffers + forward noising)\n",
    "# ----------------------------\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DCfg:\n",
    "    steps:int=400\n",
    "    beta_start:float=1e-4\n",
    "    beta_end:float=2e-2\n",
    "    beta_schedule:str=\"cosine\"  # {'linear','cosine'}\n",
    "\n",
    "def cosine_betas(T: int, s: float = 0.008):\n",
    "    r\"\"\"\n",
    "    ### TODO: implement cosine Î²_t from Î±Ì„(t)\n",
    "\n",
    "    Î±Ì„(t) = cos^2( ((t/T + s)/(1+s)) * Ï€/2 ), for t in {0,...,T}\n",
    "    Then:\n",
    "      Î²_t = min(0.999, 1 - Î±Ì„(t+1)/Î±Ì„(t))   for t = 0..T-1\n",
    "    Return float32 tensor shape (T,)\n",
    "    \"\"\"\n",
    "    # ====== Implement here ======\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, cfg: DCfg):\n",
    "        r\"\"\"\n",
    "        ### TODO: build buffers from Î²_t\n",
    "          Î±_t       = 1 - Î²_t\n",
    "          Î±Ì„_t      = âˆ_{s=1}^t Î±_s\n",
    "          sqrt_ab   = âˆš(Î±Ì„_t)\n",
    "          sqrt_1mab = âˆš(1 - Î±Ì„_t)\n",
    "          sqrt_ra   = âˆš(1/Î±_t)\n",
    "          post_var  = Î²_t * (1 - Î±Ì„_{t-1}) / (1 - Î±Ì„_t)   with Î±Ì„_0 = 1\n",
    "        \"\"\"\n",
    "        self.cfg = cfg\n",
    "        T = cfg.steps\n",
    "        self.T = T\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def to_(self, d: torch.device):\n",
    "        for k,v in vars(self).items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                setattr(self, k, v.to(d))\n",
    "        return self\n",
    "\n",
    "    def q_sample(self, x0: torch.Tensor, t: torch.Tensor, eps: torch.Tensor=None):\n",
    "        r\"\"\"\n",
    "        ### TODO: forward noising\n",
    "          x_t = âˆš(Î±Ì„_t) * x0 + âˆš(1 - Î±Ì„_t) * Îµ,   Îµ~N(0,I)\n",
    "        Return (x_t, Îµ). Use provided Îµ if not None.\n",
    "        \"\"\"\n",
    "        # ====== Implement here ======\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# EMA (GIVEN)\n",
    "# ----------------------------\n",
    "class EMA:\n",
    "    def __init__(self, model: nn.Module, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.detach().clone() for k,v in model.state_dict().items()}\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module):\n",
    "        for k, v in model.state_dict().items():\n",
    "            if v.dtype.is_floating_point:\n",
    "                self.shadow[k].mul_(self.decay).add_(v, alpha=1.0 - self.decay)\n",
    "            else:\n",
    "                self.shadow[k] = v.detach().clone()\n",
    "    def copy_to(self, model: nn.Module):\n",
    "        model.load_state_dict(self.shadow, strict=True)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Pred space helpers & DDIM step\n",
    "# ----------------------------\n",
    "def to_eps_from_pred(pred_type, out, xt, sqrt_ab_t, sqrt_1mab_t):\n",
    "    r\"\"\"\n",
    "    ### TODO: map network output 'out' to (ÎµÌ‚, xÌ‚0) depending on prediction space.\n",
    "\n",
    "      If pred_type == 'eps':\n",
    "        ÎµÌ‚   = out\n",
    "        xÌ‚0  = (xt - âˆš(1-Î±Ì„_t)*ÎµÌ‚)/âˆš(Î±Ì„_t)\n",
    "\n",
    "      If pred_type == 'x0':\n",
    "        xÌ‚0  = out\n",
    "        ÎµÌ‚   = (xt - âˆš(Î±Ì„_t)*xÌ‚0)/âˆš(1-Î±Ì„_t)\n",
    "\n",
    "      If pred_type == 'v':\n",
    "        xÌ‚0  = âˆš(Î±Ì„_t)*xt - âˆš(1-Î±Ì„_t)*out\n",
    "        ÎµÌ‚   = âˆš(1-Î±Ì„_t)*xt + âˆš(Î±Ì„_t)*out\n",
    "    \"\"\"\n",
    "    # ====== Implement here ======\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ddim_p_step(net, dd, x_t, m, y, t, t_prev, pred_type=\"v\", self_cond=False, x0_sc=None, eta=0.0, coord_conv=False):\n",
    "    r\"\"\"\n",
    "    ### TODO: DDIM deterministic step (Î·=0) with optional noise (Î·>0):\n",
    "      aÌ„_t = Î±Ì„_t, aÌ„_{t'} = Î±Ì„_{t_prev} [or 1 if t_prev=None]\n",
    "      Ïƒ_t = Î· * sqrt( (1 - aÌ„_{t'})/(1 - aÌ„_t) * (1 - aÌ„_t / aÌ„_{t'}) )\n",
    "      x_{t'} = âˆš(aÌ„_{t'}) * xÌ‚0 + âˆš(1 - aÌ„_{t'} - Ïƒ_t^2) * ÎµÌ‚  + 1_{Î·>0} * Ïƒ_t * z\n",
    "\n",
    "    Inputs include conditioning channels [x_t, m, y, (x0_sc), (coords?)].\n",
    "    Return (x_{t'}, xÌ‚0).\n",
    "    \"\"\"\n",
    "    # ====== Implement here ======\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def enforce_known(dd, x_t, y, m, t, z_fixed=None):\n",
    "    r\"\"\"\n",
    "    Per-step data-consistency on known pixels (m=1):\n",
    "      y_t = âˆš(Î±Ì„_t) * y + âˆš(1-Î±Ì„_t) * z_t\n",
    "      x_t â† m âŠ™ y_t  +  (1-m) âŠ™ x_t\n",
    "    If z_fixed is provided, reuse it; otherwise use zeros for stability.\n",
    "    \"\"\"\n",
    "    z = torch.zeros_like(y) if z_fixed is None else z_fixed\n",
    "    y_t = dd.sqrt_ab[t].view(-1,1,1,1) * y + dd.sqrt_1mab[t].view(-1,1,1,1) * z\n",
    "    return m * y_t + (1.0 - m) * x_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55b3ba",
   "metadata": {},
   "source": [
    "## 6. Loss & Inference _(GIVEN â€” do not modify)_\n",
    "\n",
    "Implements training loss and the DDIM inpainting sampler used at test time.\n",
    "\n",
    "- **`p2_weight(a_bar_t, k, gamma)`** â€” SNR-based P2 reweighting for timestep-balanced training.\n",
    "- **`loss_fn(net, dd, x0, m, y, t, ...)`** â€” Trains in chosen prediction space (`eps` / `x0` / `v`), uses `dd.q_sample` to form `(x_t, Îµ)`, optional **self-conditioning** and **coord-conv**, pixelwise **L2** with **hole upweighting** via `hole_weight`, and multiplies by **P2** weights; returns the mean loss.\n",
    "- **`inpaint(net, dd, y, m, ...)`** â€” DDIM inpainting loop over a timestep grid; supports deterministic (`Î·=0`) or noisy (`Î·>0`) updates, optional `init_from_y`, per-step **data consistency** via `enforce_known` repeated `dc_repeats` times, optional fixed noise for DC, and optional self-conditioning across steps.\n",
    "\n",
    "> **Heads-up:** Keep the sampler `pred_type` consistent with training. Lower `steps` if memory is tight; `dc_repeats=2` often improves seam quality; use `Î·=0` for classic DDIM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859289d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2_weight(a_bar_t, k=1.0, gamma=1.0):\n",
    "    snr = a_bar_t / (1.0 - a_bar_t + 1e-8)\n",
    "    return torch.pow(k + snr, -gamma)\n",
    "\n",
    "def loss_fn(net, dd, x0, m, y, t, pred_type=\"v\", hole_weight=5.0, p2_k=1.0, p2_gamma=1.0,\n",
    "            self_cond=False, coord_conv=False):\n",
    "    \"\"\"\n",
    "    Training loss (noise prediction in chosen space) with hole upweight + p2.\n",
    "    \"\"\"\n",
    "    xt, eps = dd.q_sample(x0, t)\n",
    "    B, _, H, W = x0.shape\n",
    "\n",
    "    # coord-conv channels\n",
    "    coords = None\n",
    "    if coord_conv:\n",
    "        yy, xx = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, H, device=x0.device),\n",
    "            torch.linspace(-1, 1, W, device=x0.device),\n",
    "            indexing=\"ij\"\n",
    "        )\n",
    "        coords = torch.stack([xx, yy], dim=0).expand(B, -1, -1, -1)  # (B,2,H,W)\n",
    "\n",
    "    # self-conditioning (50%): zero-SC prepass to get x0_sc\n",
    "    if self_cond and (random.random() < 0.5):\n",
    "        din0 = [xt, m, y, torch.zeros_like(x0)]\n",
    "        if coords is not None: din0.append(coords)\n",
    "        out0 = net(torch.cat(din0, dim=1), t)\n",
    "        sqrt_ab_t   = dd.sqrt_ab[t].view(-1,1,1,1)\n",
    "        sqrt_1mab_t = dd.sqrt_1mab[t].view(-1,1,1,1)\n",
    "        _, x0_hat0 = to_eps_from_pred(pred_type, out0, xt, sqrt_ab_t, sqrt_1mab_t)\n",
    "        sc = x0_hat0.detach()\n",
    "        din = [xt, m, y, sc]\n",
    "    else:\n",
    "        din = [xt, m, y] + ([torch.zeros_like(x0)] if self_cond else [])\n",
    "\n",
    "    if coords is not None:\n",
    "        din.append(coords)\n",
    "\n",
    "    out = net(torch.cat(din, dim=1), t)\n",
    "\n",
    "    # target in chosen pred space\n",
    "    if pred_type == \"eps\":\n",
    "        target = eps\n",
    "    elif pred_type == \"x0\":\n",
    "        target = x0\n",
    "    else:  # 'v'\n",
    "        target = dd.sqrt_ab[t].view(-1,1,1,1) * eps - dd.sqrt_1mab[t].view(-1,1,1,1) * x0\n",
    "\n",
    "    # pixelwise L2 with hole upweight + p2 weighting\n",
    "    per_pix = (out - target)**2\n",
    "    if hole_weight and hole_weight != 1.0:\n",
    "        weight_mask = 1.0 + (hole_weight - 1.0) * (1.0 - m)\n",
    "        per_pix = per_pix * weight_mask\n",
    "\n",
    "    w = p2_weight(dd.a_bar[t], k=p2_k, gamma=p2_gamma).view(-1,1,1,1)\n",
    "    return (w * per_pix).mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inpaint(net, dd, y, m, steps=50, d=None, dc_repeats=2, dc_fixed_z=True,\n",
    "            pred_type=\"v\", self_cond=False, init_from_y=True,\n",
    "            eta=0.0, coord_conv=False):\n",
    "    device = y.device\n",
    "    tau = torch.linspace(0, dd.T - 1, steps, device=device).round().long()\n",
    "    B = y.size(0)\n",
    "    if init_from_y:\n",
    "        x = m * y + (1.0 - m) * torch.randn_like(y)\n",
    "    else:\n",
    "        x = torch.randn_like(y)\n",
    "    z0 = torch.randn_like(y) if dc_fixed_z else None\n",
    "    x0_sc = None\n",
    "\n",
    "    for i in reversed(range(len(tau))):\n",
    "        ti = tau[i]; tb = ti.repeat(B)\n",
    "        for _ in range(max(1, dc_repeats)):\n",
    "            x = enforce_known(dd, x, y, m, tb, z_fixed=z0)\n",
    "\n",
    "        t_prev = tau[i-1] if i > 0 else None\n",
    "        x, x0_sc = ddim_p_step(net, dd, x, m, y, tb, t_prev, pred_type=pred_type,\n",
    "                               self_cond=self_cond, x0_sc=x0_sc, eta=eta, coord_conv=coord_conv)\n",
    "    x = m * y + (1.0 - m) * x\n",
    "    return x.clamp(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bb0fb",
   "metadata": {},
   "source": [
    "## 7. Train / Sample / Eval helpers _(GIVEN â€” no argparse)_\n",
    "\n",
    "High-level helpers to **train**, **sample**, and **evaluate** without CLI flags.\n",
    "\n",
    "- **`train(...)`** â€” Runs full training with AdamW, LR **warmup**, **EMA** tracking, optional **grad accumulation** & **grad clipping**. Periodically saves **inpainting panels** (`outputs/inpaint/panel_*.png`) using the EMA copy, and finally writes a checkpoint to `outputs/inpaint/last.pt` (with config).\n",
    "- **`sample_cmd(...)`** â€” Loads the checkpoint (prefers **EMA** weights), rebuilds diffusion and UNet from saved config, inpaints a test batch, and saves `outputs/inpaint/samples.png`.\n",
    "- **`eval_cmd(...)`** â€” Loads the checkpoint (prefers **EMA**), inpaints the MNIST test set up to `n_eval` images, computes **hole-only PSNR/L1**, and writes `results/inpaint_metrics.json`.\n",
    "\n",
    "> **Heads-up:**  \n",
    "> â€¢ Keep `pred` consistent between training and sampling.  \n",
    "> â€¢ If memory is tight, lower `batch_size`, raise `grad_accum`, or reduce `steps/sample_steps`.  \n",
    "> â€¢ Outputs are saved under `outputs/inpaint/` and metrics under `results/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=3, batch_size=128, lr=2e-4, steps=400,\n",
    "          beta_start=1e-4, beta_end=2e-2, beta_schedule=\"cosine\",\n",
    "          base=96, emb=384, sample_every=400, sample_steps=50,\n",
    "          center_box=12, dc_repeats=2, dc_fixed_z=True,\n",
    "          pred=\"v\", p2_k=1.0, p2_gamma=1.0, hole_weight=5.0,\n",
    "          seed=42, clip_grad=1.0, ema_decay=0.999, warmup_steps=1000,\n",
    "          self_cond=True, eta=0.0, coord_conv=True,\n",
    "          grad_accum:int=1):\n",
    "    seed_all(seed); d = dev()\n",
    "    train_loader, test_loader, (C,H,W) = get_mnist_loader(batch_size=batch_size, num_workers=2)\n",
    "\n",
    "    in_extra = (1 if self_cond else 0) + (2 if coord_conv else 0)\n",
    "    in_ch = 3 + in_extra\n",
    "    net = UNetDeep(in_ch=in_ch, base=base, emb=emb, out_ch=1, dropout=0.1, use_attn=True).to(d)\n",
    "\n",
    "    dd = Diffusion(DCfg(steps=steps, beta_start=beta_start, beta_end=beta_end,\n",
    "                        beta_schedule=beta_schedule)).to_(d)\n",
    "\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    ema = EMA(net, decay=ema_decay)\n",
    "\n",
    "    step_i = 0\n",
    "    scaler = 1.0 / max(1, grad_accum)\n",
    "    for ep in range(epochs):\n",
    "        running = 0.0\n",
    "        for it,(x,_) in enumerate(tqdm(train_loader, desc=f\"Epoch {ep+1}/{epochs}\")):\n",
    "            x = x.to(d)\n",
    "            B = x.size(0)\n",
    "            m = make_center_box_mask(B,H,W, box=center_box).to(d)\n",
    "            y = m * x\n",
    "            t = torch.randint(0, steps, (B,), device=d, dtype=torch.long)\n",
    "\n",
    "            if warmup_steps and step_i < warmup_steps:\n",
    "                warm_lr = lr * float(step_i + 1) / float(warmup_steps)\n",
    "                for pg in opt.param_groups: pg[\"lr\"] = warm_lr\n",
    "\n",
    "            loss = loss_fn(net, dd, x, m, y, t,\n",
    "                           pred_type=pred, hole_weight=hole_weight,\n",
    "                           p2_k=p2_k, p2_gamma=p2_gamma, self_cond=self_cond,\n",
    "                           coord_conv=coord_conv)\n",
    "            (loss * scaler).backward()\n",
    "            running += float(loss)\n",
    "\n",
    "            if ((it + 1) % grad_accum) == 0:\n",
    "                if clip_grad and clip_grad > 0:\n",
    "                    nn.utils.clip_grad_norm_(net.parameters(), max_norm=clip_grad)\n",
    "                opt.step(); opt.zero_grad(); ema.update(net)\n",
    "                step_i += 1\n",
    "\n",
    "                if (step_i % sample_every) == 0:\n",
    "                    with torch.no_grad():\n",
    "                        net_ema = UNetDeep(in_ch=in_ch, base=base, emb=emb, out_ch=1).to(d)\n",
    "                        ema.copy_to(net_ema); net_ema.eval()\n",
    "                        idx = slice(0, min(16, B))\n",
    "                        comp = inpaint(net_ema, dd, y[idx], m[idx], steps=sample_steps, d=d,\n",
    "                                       dc_repeats=dc_repeats, dc_fixed_z=dc_fixed_z,\n",
    "                                       pred_type=pred, self_cond=self_cond, init_from_y=True,\n",
    "                                       eta=eta, coord_conv=coord_conv)\n",
    "                        panel = torch.cat([x[idx], y[idx], comp], dim=0)\n",
    "                        save_grid(panel, f\"outputs/inpaint/panel_{step_i:06d}.png\", nrow=panel.size(0)//3)\n",
    "                        del net_ema\n",
    "\n",
    "        print(f\"[Epoch {ep+1}] mean loss: {running / max(1,len(train_loader)):.4f}\")\n",
    "\n",
    "    ensure_dir(\"outputs/inpaint\")\n",
    "    torch.save({\n",
    "        \"net\": net.state_dict(),\n",
    "        \"ema\": ema.shadow,\n",
    "        \"cfg\": dict(epochs=epochs, batch_size=batch_size, lr=lr, steps=steps,\n",
    "                    beta_start=beta_start, beta_end=beta_end, beta_schedule=beta_schedule,\n",
    "                    base=base, emb=emb, sample_every=sample_every, sample_steps=sample_steps,\n",
    "                    center_box=center_box, dc_repeats=dc_repeats, dc_fixed_z=dc_fixed_z,\n",
    "                    pred=pred, p2_k=p2_k, p2_gamma=p2_gamma, hole_weight=hole_weight,\n",
    "                    seed=seed, clip_grad=clip_grad, ema_decay=ema_decay, warmup_steps=warmup_steps,\n",
    "                    self_cond=int(self_cond), eta=eta, coord_conv=int(coord_conv),\n",
    "                    grad_accum=grad_accum)},\n",
    "               \"outputs/inpaint/last.pt\")\n",
    "\n",
    "    # Final panel with EMA\n",
    "    with torch.no_grad():\n",
    "        _, test_loader, _ = get_mnist_loader(batch_size=16, num_workers=0)\n",
    "        x,_ = next(iter(test_loader))\n",
    "        x = x.to(d); B = min(16, x.size(0))\n",
    "        m = make_center_box_mask(B,32,32, box=center_box).to(d)\n",
    "        y = m * x[:B]\n",
    "        net_ema = UNetDeep(in_ch=in_ch, base=base, emb=emb, out_ch=1).to(d)\n",
    "        pkg = safe_torch_load(\"outputs/inpaint/last.pt\", map_location=\"cpu\")\n",
    "        state = pkg.get(\"ema\", pkg.get(\"net\"))\n",
    "        net_ema.load_state_dict(state, strict=False)\n",
    "        net_ema.eval()\n",
    "        comp = inpaint(net_ema, dd, y, m, steps=sample_steps, d=d,\n",
    "                       dc_repeats=dc_repeats, dc_fixed_z=dc_fixed_z,\n",
    "                       pred_type=pred, self_cond=self_cond, init_from_y=True,\n",
    "                       eta=eta, coord_conv=coord_conv)\n",
    "        panel = torch.cat([x[:B], y, comp], dim=0)\n",
    "        save_grid(panel, \"outputs/inpaint/panel_final.png\", nrow=B)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_cmd(ckpt=\"outputs/inpaint/last.pt\", n=16, steps=50,\n",
    "               center_box=12, dc_repeats=2, dc_fixed_z=True,\n",
    "               pred=\"v\", self_cond=True, init_from_y=True,\n",
    "               eta=0.0, coord_conv=True):\n",
    "    d = dev()\n",
    "    pkg = safe_torch_load(ckpt, map_location=\"cpu\")\n",
    "    cfg = pkg.get(\"cfg\", {})\n",
    "    base = cfg.get(\"base\", 96); emb = cfg.get(\"emb\", 384)\n",
    "    dd = Diffusion(DCfg(steps=cfg.get(\"steps\", steps),\n",
    "                        beta_start=cfg.get(\"beta_start\", 1e-4),\n",
    "                        beta_end=cfg.get(\"beta_end\", 2e-2),\n",
    "                        beta_schedule=cfg.get(\"beta_schedule\",\"cosine\"))).to_(d)\n",
    "    in_extra = (1 if int(cfg.get(\"self_cond\", 1)) else 0) + (2 if int(cfg.get(\"coord_conv\", 1)) else 0)\n",
    "    in_ch = 3 + in_extra\n",
    "    net = UNetDeep(in_ch=in_ch, base=base, emb=emb, out_ch=1).to(d)\n",
    "    state = pkg.get(\"ema\", pkg.get(\"net\"))\n",
    "    net.load_state_dict(state, strict=False); net.eval()\n",
    "\n",
    "    _, test_loader, (C,H,W) = get_mnist_loader(batch_size=n, num_workers=0)\n",
    "    x,_ = next(iter(test_loader))\n",
    "    x = x.to(d); B = min(n, x.size(0))\n",
    "    m = make_center_box_mask(B,H,W, box=center_box).to(d)\n",
    "    y = m * x[:B]\n",
    "    comp = inpaint(net, dd, y, m, steps=steps, d=d,\n",
    "                   dc_repeats=dc_repeats, dc_fixed_z=dc_fixed_z,\n",
    "                   pred_type=pred, self_cond=bool(int(cfg.get(\"self_cond\",1))),\n",
    "                   init_from_y=init_from_y, eta=float(cfg.get(\"eta\", 0.0)),\n",
    "                   coord_conv=bool(int(cfg.get(\"coord_conv\",1))))\n",
    "    panel = torch.cat([x[:B], y, comp], dim=0)\n",
    "    save_grid(panel, \"outputs/inpaint/samples.png\", nrow=B)\n",
    "    print(\"Wrote outputs/inpaint/samples.png\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_cmd(ckpt=\"outputs/inpaint/last.pt\", batch_size=256, n_eval=500, steps=50,\n",
    "             center_box=12, dc_repeats=2, dc_fixed_z=True, pred=\"v\",\n",
    "             self_cond=True, init_from_y=True, eta=0.0,\n",
    "             coord_conv=True, seed=123):\n",
    "    seed_all(seed); d = dev()\n",
    "    pkg = safe_torch_load(ckpt, map_location=\"cpu\")\n",
    "    cfg = pkg.get(\"cfg\", {})\n",
    "    base = cfg.get(\"base\", 96); emb = cfg.get(\"emb\", 384)\n",
    "    dd = Diffusion(DCfg(steps=cfg.get(\"steps\", steps),\n",
    "                        beta_start=cfg.get(\"beta_start\", 1e-4),\n",
    "                        beta_end=cfg.get(\"beta_end\", 2e-2),\n",
    "                        beta_schedule=cfg.get(\"beta_schedule\",\"cosine\"))).to_(d)\n",
    "    in_extra = (1 if int(cfg.get(\"self_cond\", 1)) else 0) + (2 if int(cfg.get(\"coord_conv\", 1)) else 0)\n",
    "    in_ch = 3 + in_extra\n",
    "    net = UNetDeep(in_ch=in_ch, base=base, emb=emb, out_ch=1).to(d)\n",
    "    state = pkg.get(\"ema\", pkg.get(\"net\"))\n",
    "    net.load_state_dict(state, strict=False); net.eval()\n",
    "\n",
    "    _, test_loader, (C,H,W) = get_mnist_loader(batch_size=batch_size, num_workers=2)\n",
    "    tot_psnr, tot_l1, tot_n = 0.0, 0.0, 0\n",
    "    for x,_ in test_loader:\n",
    "        x = x.to(d); B = x.size(0)\n",
    "        m = make_center_box_mask(B,H,W, box=center_box).to(d)\n",
    "        y = m * x\n",
    "        comp = inpaint(net, dd, y, m, steps=steps, d=d,\n",
    "                       dc_repeats=dc_repeats, dc_fixed_z=dc_fixed_z,\n",
    "                       pred_type=pred, self_cond=bool(int(cfg.get(\"self_cond\",1))),\n",
    "                       init_from_y=init_from_y, eta=float(cfg.get(\"eta\", 0.0)),\n",
    "                       coord_conv=bool(int(cfg.get(\"coord_conv\",1))))\n",
    "        tot_psnr += psnr_on_mask(comp, x, m) * B\n",
    "        tot_l1   += l1_on_mask(comp, x, m) * B\n",
    "        tot_n    += B\n",
    "        if tot_n >= n_eval: break\n",
    "    avg_psnr = float(tot_psnr / max(1,tot_n))\n",
    "    avg_l1   = float(tot_l1 / max(1,tot_n))\n",
    "    ensure_dir(\"results\")\n",
    "    with open(\"results/inpaint_metrics.json\", \"w\") as f:\n",
    "        json.dump({\"psnr_hole\": avg_psnr, \"l1_hole\": avg_l1}, f, indent=2)\n",
    "    print(json.dumps({\"psnr_hole\": avg_psnr, \"l1_hole\": avg_l1}, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed4a00",
   "metadata": {},
   "source": [
    "## 8. How to run (after you finish the TODOs)\n",
    "\n",
    "1. **Implement all TODOs** in **Section 5** (embedding, UNet, cosine betas, diffusion buffers/q_sample, pred mapping, DDIM step).\n",
    "2. **Train** for a few epochs (Colab-friendly config below).\n",
    "3. **Sample** to visualize results.\n",
    "4. **Evaluate** PSNR/L1 on the hole region.\n",
    "\n",
    "> ðŸ’¡ Tip: Start small for quick iteration â€” e.g., `epochs=3`, `steps=200`, `sample_steps=25`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35537754",
   "metadata": {},
   "source": [
    "## 9. Train _(run after completing Section 5)_\n",
    "\n",
    "Runs AdamW with EMA and saves:\n",
    "- **Checkpoint:** `outputs/inpaint/last.pt`\n",
    "- **Panels (every `sample_every`):** `outputs/inpaint/panel_*.png`\n",
    "\n",
    "**Edit the config** to fit your GPU (lower `batch_size`, reduce `steps/sample_steps`, or increase `grad_accum` if you hit Out of Memory).  \n",
    "> Note: This cell will error until all **TODOs** in Section 5 are implemented. Keep `pred` consistent with later sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c777cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    lr=2e-4,\n",
    "    steps=400,\n",
    "    sample_every=400,\n",
    "    sample_steps=50,\n",
    "    center_box=12,\n",
    "    dc_repeats=2,\n",
    "    dc_fixed_z=True,\n",
    "    pred=\"v\",\n",
    "    p2_k=1.0,\n",
    "    p2_gamma=1.0,\n",
    "    hole_weight=5.0,\n",
    "    seed=42,\n",
    "    clip_grad=1.0,\n",
    "    ema_decay=0.999,\n",
    "    warmup_steps=1000,\n",
    "    self_cond=True,\n",
    "    eta=0.0,\n",
    "    coord_conv=True,\n",
    "    grad_accum=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6afe90",
   "metadata": {},
   "source": [
    "## 10. Sample _(after training)_\n",
    "\n",
    "Loads `outputs/inpaint/last.pt` (prefers **EMA** weights), rebuilds UNet/Diffusion from the saved config, inpaints a small test batch, and writes **`outputs/inpaint/samples.png`**.\n",
    "\n",
    "> Keep `pred` consistent with training. You can adjust `steps`, `center_box`, `eta`, or `init_from_y` for different looks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_cmd(\n",
    "    ckpt=\"outputs/inpaint/last.pt\",\n",
    "    n=16,\n",
    "    steps=50,\n",
    "    center_box=12,\n",
    "    dc_repeats=2,\n",
    "    dc_fixed_z=True,\n",
    "    pred=\"v\",\n",
    "    self_cond=True,\n",
    "    init_from_y=True,\n",
    "    eta=0.0,\n",
    "    coord_conv=True,\n",
    ")\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=\"outputs/inpaint/samples.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6b0f3",
   "metadata": {},
   "source": [
    "## 11. Evaluate _(hole-only PSNR/L1)_\n",
    "\n",
    "Runs inpainting on the MNIST **test** split up to `n_eval` images, computes **PSNR/L1 over the hole region**, and saves **`results/inpaint_metrics.json`** (also prints the values).\n",
    "\n",
    "> For fair comparison, match `steps` and `center_box` with training; use `Î·=0` for deterministic DDIM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31954a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cmd(\n",
    "    ckpt=\"outputs/inpaint/last.pt\",\n",
    "    batch_size=256,\n",
    "    n_eval=500,\n",
    "    steps=50,\n",
    "    center_box=12,\n",
    "    dc_repeats=2,\n",
    "    dc_fixed_z=True,\n",
    "    pred=\"v\",\n",
    "    self_cond=True,\n",
    "    init_from_y=True,\n",
    "    eta=0.0,\n",
    "    coord_conv=True,\n",
    "    seed=123,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
